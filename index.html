<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>shilinlee&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="shilinlee&#39;s blog">
<meta property="og:url" content="https://boyl40.github.com/index.html">
<meta property="og:site_name" content="shilinlee&#39;s blog">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="shilinlee&#39;s blog">
  
    <link rel="alternate" href="/atom.xml" title="shilinlee&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://boyl40.github.com"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">shilinlee&#39;s blog</a>
      </h1>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="hadoop-大数据处理框架Hadoop的学习" class="article article-type-hadoop" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/22/大数据处理框架Hadoop的学习/" class="article-date">
  <time datetime="2019-06-22T05:56:58.000Z" itemprop="datePublished">2019-06-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/22/大数据处理框架Hadoop的学习/">大数据处理框架Hadoop的学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><ul>
<li>Hadoop是基于Java语言开发的，具有很好的跨平台特性，并且可以部署在廉价的计算机集群中</li>
<li>Hadoop的核心是分布式文件系统HDFS（Hadoop Distributed File System）和MapReduce。</li>
<li>经过多年发展，Hadoop项目已经变得非常成熟和完善，包括Common、Avro、Zookeeper、HDFS、MapReduce、HBase、Hive、Chukwa、Pig等子项目，其中，HDFS和MapReduce是Hadoop的两大核心组件。</li>
</ul>
<h1 id="Hadoop现状"><a href="#Hadoop现状" class="headerlink" title="Hadoop现状"></a>Hadoop现状</h1><ul>
<li>应用架构</li>
</ul>
<p><img src="/images/image-20190622140440199.png" alt="Hadoop应用架构"></p>
<ul>
<li><p>项目结构</p>
<p>Hadoop的项目结构不断丰富发展，已经形成一个丰富的Hadoop生态系统</p>
<p><img src="/images/image-20190622141152579.png" alt="Hadoop project structure"></p>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th style="text-align:left"><strong>功能</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS</td>
<td style="text-align:left">分布式文件系统</td>
</tr>
<tr>
<td>MapReduce</td>
<td style="text-align:left">分布式并行编程模型</td>
</tr>
<tr>
<td>YARN</td>
<td style="text-align:left">资源管理和调度器</td>
</tr>
<tr>
<td>Tez</td>
<td style="text-align:left">运行在YARN之上的下一代Hadoop查询处理框架</td>
</tr>
<tr>
<td>Hive</td>
<td style="text-align:left">Hadoop上的数据仓库</td>
</tr>
<tr>
<td>HBase</td>
<td style="text-align:left">Hadoop上的非关系型的分布式数据库</td>
</tr>
<tr>
<td>Pig</td>
<td style="text-align:left">一个基于Hadoop的大规模数据分析平台，提供类似SQL的查询语言Pig Latin</td>
</tr>
<tr>
<td>Sqoop</td>
<td style="text-align:left">用于在Hadoop与传统数据库之间进行数据传递</td>
</tr>
<tr>
<td>Oozie</td>
<td style="text-align:left">Hadoop上的工作流管理系统</td>
</tr>
<tr>
<td>Zookeeper</td>
<td style="text-align:left">提供分布式协调一致性服务</td>
</tr>
<tr>
<td>Storm</td>
<td style="text-align:left">流计算框架</td>
</tr>
<tr>
<td>Flume</td>
<td style="text-align:left">一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统</td>
</tr>
<tr>
<td>Ambari</td>
<td style="text-align:left">Hadoop快速部署工具，支持Apache   Hadoop集群的供应、管理和监控</td>
</tr>
<tr>
<td>Kafka</td>
<td style="text-align:left">一种高吞吐量的分布式发布订阅消息系统，可以处理消费者规模的网站中的所有动作流数据</td>
</tr>
<tr>
<td>Spark</td>
<td style="text-align:left">类似于Hadoop MapReduce的通用并行框架</td>
</tr>
</tbody>
</table>
<h1 id="Hadoop集群的部署与使用"><a href="#Hadoop集群的部署与使用" class="headerlink" title="Hadoop集群的部署与使用"></a>Hadoop集群的部署与使用</h1><h2 id="集群节点类型"><a href="#集群节点类型" class="headerlink" title="集群节点类型"></a>集群节点类型</h2><ul>
<li>Hadoop框架中最核心的设计是为海量数据提供存储的<strong>HDFS</strong>和对数据进行计算的<strong>MapReduce</strong></li>
<li><p>MapReduce的作业主要包括：</p>
<ul>
<li>从磁盘或从网络读取数据，即IO密集工作；</li>
<li>计算数据，即CPU密集工作</li>
</ul>
</li>
<li><p>一个基本的Hadoop集群中的节点主要有</p>
<ul>
<li>NameNode：负责协调集群中的数据存储</li>
<li>DataNode：存储被拆分的数据块</li>
<li>JobTracker：协调数据计算任务</li>
<li>TaskTracker：负责执行由JobTracker指派的任务</li>
<li>SecondaryNameNode：帮助NameNode收集文件系统运行的状态信息</li>
</ul>
</li>
</ul>
<h2 id="集群的建立与安装"><a href="#集群的建立与安装" class="headerlink" title="集群的建立与安装"></a>集群的建立与安装</h2><ul>
<li><p>为了缓解安装和维护每个节点上相同的软件的负担，可以使用一个自动化方法实现完全自动化安装，比如Red Hat Linux’ Kickstart、Debian或者<strong>Docker</strong></p>
</li>
<li><p>自动化安装部署工具，会通过记录在安装过程中对于各个选项的回答来完成自动化安装过程。</p>
</li>
</ul>
<h2 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h2><ul>
<li><p>Hadoop自带有一些基准测试程序，被打包在测试程序JAR文件中</p>
</li>
<li><p>用TestDFSIO基准测试，来测试HDFS的IO性能</p>
</li>
<li><p>用排序测试MapReduce：Hadoop自带一个部分排序的程序，这个测试过程的整个数据集都会通过洗牌（Shuffle）传输至Reducer，可以充分测试MapReduce的性能</p>
</li>
</ul>
<h1 id="Hadoop的发展"><a href="#Hadoop的发展" class="headerlink" title="Hadoop的发展"></a>Hadoop的发展</h1><h2 id="改进核心组件"><a href="#改进核心组件" class="headerlink" title="改进核心组件"></a>改进核心组件</h2><ul>
<li>自身核心两大组件<strong>MapReduce</strong>和<strong>HDFS</strong>的架构设计改进</li>
</ul>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th><strong>Hadoop1.0**</strong>的问题**</th>
<th><strong>Hadoop2.0**</strong>的改进**</th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS</td>
<td>单一名称节点，存在单点失效问题</td>
<td>设计了HDFS   HA，提供名称节点热备机制</td>
</tr>
<tr>
<td>HDFS</td>
<td>单一命名空间，无法实现资源隔离</td>
<td>设计了HDFS   Federation，管理多个命名空间</td>
</tr>
<tr>
<td>MapReduce</td>
<td>资源管理效率低</td>
<td>设计了新的资源管理框架YARN</td>
</tr>
</tbody>
</table>
<h2 id="其他组件不断丰富"><a href="#其他组件不断丰富" class="headerlink" title="其他组件不断丰富"></a>其他组件不断丰富</h2><ul>
<li>Pig</li>
<li>Tez</li>
<li><strong>Spark</strong></li>
<li><strong>Kafka</strong></li>
</ul>
<table>
<thead>
<tr>
<th><strong>组件</strong></th>
<th style="text-align:left"><strong>功能</strong></th>
<th><strong>解决Hadoop中存在的问题</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Pig</strong></td>
<td style="text-align:left">处理大规模数据的脚本语言，用户只需要编写几条简单的语句，系统会自动转换为MapReduce作业</td>
<td>抽象层次低，需要手工编写大量代码</td>
</tr>
<tr>
<td><strong>Spark</strong></td>
<td style="text-align:left">基于内存的分布式并行编程框架，具有较高的实时性，并且较好支持迭代计算</td>
<td>延迟高，而且不适合执行迭代计算</td>
</tr>
<tr>
<td><strong>Oozie</strong></td>
<td style="text-align:left">工作流和协作服务引擎，协调Hadoop上运行的不同任务</td>
<td>没有提供作业（Job）之间依赖关系管理机制，需要用户自己处理作业之间依赖关系</td>
</tr>
<tr>
<td><strong>Tez</strong></td>
<td style="text-align:left">支持DAG作业的计算框架，对作业的操作进行重新分解和组合，形成一个大的DAG作业，减少不必要操作</td>
<td>不同的MapReduce任务之间存在重复操作，降低了效率</td>
</tr>
<tr>
<td><strong>Kafka</strong></td>
<td style="text-align:left">分布式发布订阅消息系统，一般作为企业大数据分析平台的数据交换枢纽，不同类型的分布式系统可以统一接入到Kafka，实现和Hadoop各个组件之间的不同类型数据的实时高效交换</td>
<td>Hadoop生态系统中各个组件和其他产品之间缺乏统一的、高效的数据交换中介</td>
</tr>
</tbody>
</table>
<h2 id="HDFS-HA（high-availiability）"><a href="#HDFS-HA（high-availiability）" class="headerlink" title="HDFS HA（high availiability）"></a>HDFS HA（high availiability）</h2><h3 id="HDFS1-0"><a href="#HDFS1-0" class="headerlink" title="HDFS1.0"></a>HDFS1.0</h3><ul>
<li><p><strong>NameNode</strong></p>
<ul>
<li><p>在磁盘上：FsImage和EditLog</p>
</li>
<li><p>在内存中：映射信息，即文件包含哪些块，每个块存储在哪个数据节点</p>
</li>
</ul>
</li>
<li><p><strong>SecondryNameNode</strong></p>
<ul>
<li>SecondaryNameNode会定期和NameNode通信</li>
<li>从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下</li>
<li><p>执行EditLog和FsImage文件合并</p>
</li>
<li><p>将新的FsImage文件发送到NameNode节点上</p>
</li>
<li>NameNode使用新的FsImage和EditLog（缩小了）</li>
</ul>
</li>
</ul>
<h3 id="HDFS-2-0"><a href="#HDFS-2-0" class="headerlink" title="HDFS 2.0"></a>HDFS 2.0</h3><ul>
<li><p>HDFS HA（High Availability）是为了解决单点故障问题</p>
</li>
<li><p>HA集群设置两个名称节点，“活跃（Active）”和“待命（Standby）”</p>
</li>
<li><p>两种名称节点的状态同步，可以借助于一个共享存储系统来实现</p>
</li>
<li><p>一旦活跃名称节点出现故障，就可以立即切换到待命名称节点</p>
</li>
<li><p>Zookeeper确保一个名称节点在对外服务</p>
</li>
<li><p>名称节点维护映射信息，数据节点同时向两个名称节点汇报信息</p>
</li>
</ul>
<p><img src="/images/image-20190622154543363.jpg" alt="image-20190622155453985"></p>
<blockquote>
<p>共享存储系统: EditLog实时同步</p>
</blockquote>
<h2 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h2><ul>
<li>HDFS集群扩展性</li>
<li>性能更高效</li>
<li>良好的隔离性</li>
</ul>
<blockquote>
<p>HDFS Federation并不能解决单点故障问题</p>
</blockquote>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><h3 id="MapReduce1-0"><a href="#MapReduce1-0" class="headerlink" title="MapReduce1.0"></a>MapReduce1.0</h3><p><img src="/images/image-20190622163927142.jpg" alt="MapReduce1.0体系结构"></p>
<h3 id="YARN设计思路"><a href="#YARN设计思路" class="headerlink" title="YARN设计思路"></a>YARN设计思路</h3><p><img src="/images/image-20190622164255883.jpg" alt="image-20190622164255883"></p>
<ul>
<li><p>到了Hadoop2.0以后，MapReduce1.0中的资源管理调度功能，被单独分离出来形成了YARN，它是一个纯粹的资源管理调度框架，而不是一个计算框架</p>
</li>
<li><p>被剥离了资源管理调度功能的MapReduce 框架就变成了MapReduce2.0，它是运行在YARN之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由YARN为其提供资源管理调度服务</p>
</li>
</ul>
<h2 id="YARN体系结构"><a href="#YARN体系结构" class="headerlink" title="YARN体系结构"></a>YARN体系结构</h2><h3 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h3><ul>
<li><p>ResourceManager（<strong>RM</strong>）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）</p>
</li>
<li><p>调度器接收来自ApplicationMaster的应用程序资源请求，把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”</p>
</li>
<li><p>容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量</p>
</li>
<li><p>调度器被设计成是一个可插拔的组件，YARN不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器</p>
</li>
<li><p>应用程序管理器（Applications Manager）负责系统中所有应用程序的管理工作，主要包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动等</p>
</li>
</ul>
<blockquote>
<p><strong>RM</strong>管理的对象是<strong>Applications Master</strong></p>
</blockquote>
<h3 id="Applications-Master"><a href="#Applications-Master" class="headerlink" title="Applications Master"></a>Applications Master</h3><p>ResourceManager接收用户提交的作业，按照作业的上下文信息以及从NodeManager收集来的容器状态信息，启动调度过程，为用户作业启动一个ApplicationMaster。</p>
<p>ApplicationMaster的主要功能是：</p>
<ul>
<li>当用户作业提交时，ApplicationMaster与ResourceManager协商获取资源，ResourceManager会以容器的形式为ApplicationMaster分配资源；</li>
<li>把获得的资源进一步分配给内部的各个任务（Map任务或Reduce任务），实现资源的“二次分配”；</li>
<li>与NodeManager保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；</li>
<li>定时向ResourceManager发送“心跳”消息，报告资源的使用情况和应用的进度信息；</li>
<li>当作业完成时，ApplicationMaster向ResourceManager注销容器，执行周期完成。</li>
</ul>
<h3 id="NodeManager"><a href="#NodeManager" class="headerlink" title="NodeManager"></a>NodeManager</h3><p>NodeManager是驻留在一个YARN集群中的每个节点上的代理，主要负责：</p>
<ul>
<li>容器生命周期管理</li>
<li>监控每个容器的资源（CPU、内存等）使用情况</li>
<li>跟踪节点健康状况</li>
<li>以“心跳”的方式与ResourceManager保持通信</li>
<li>向ResourceManager汇报作业的资源使用情况和每个容器的运行状态</li>
<li>接收来自ApplicationMaster的<strong>启动</strong>/<strong>停止</strong>容器的各种请求</li>
</ul>
<h2 id="YARN和Hadoop平台其他组件的统一部署"><a href="#YARN和Hadoop平台其他组件的统一部署" class="headerlink" title="YARN和Hadoop平台其他组件的统一部署"></a>YARN和Hadoop平台其他组件的统一部署</h2><p><img src="/images/image-20190622170206108.jpg" alt="YARN和Hadoop平台其他组件的统一部署"></p>
<h2 id="YARN的目标"><a href="#YARN的目标" class="headerlink" title="YARN的目标"></a>YARN的目标</h2><ul>
<li><p>YARN的目标就是实现“一个集群多个框架”。</p>
</li>
<li><p>由YARN为这些计算框架提供统一的资源调度管理服务，并且能够根据各种计算框架的负载需求，调整各自占用的资源，实现集群资源共享和资源弹性收缩</p>
</li>
<li>可以实现一个集群上的不同应用负载混搭，有效提高了集群的利用率</li>
<li>不同计算框架可以共享底层存储，避免了数据集跨集群移动</li>
</ul>
<h1 id="Hadoop生态系统"><a href="#Hadoop生态系统" class="headerlink" title="Hadoop生态系统"></a>Hadoop生态系统</h1><h2 id="Pig"><a href="#Pig" class="headerlink" title="Pig"></a>Pig</h2><h3 id="Pig用途"><a href="#Pig用途" class="headerlink" title="Pig用途"></a>Pig用途</h3><ul>
<li>提供了类似SQL的Pig Latin语言（包含Filter、GroupBy、Join、OrderBy等操作，同时也支持用户自定义函数）</li>
<li>允许用户通过编写简单的脚本来实现复杂的数据分析，而不需要编写复杂的MapReduce应用程序</li>
<li>Pig会自动把用户编写的脚本转换成MapReduce作业在Hadoop集群上运行，而且具备对生成的MapReduce程序进行自动优化的功能</li>
<li>用户在编写Pig程序的时候，不需要关心程序的运行效率，这就大大减少了用户编程时间</li>
</ul>
<h3 id="Pig书写格式"><a href="#Pig书写格式" class="headerlink" title="Pig书写格式"></a>Pig书写格式</h3><p>Pig语句通常按照如下的格式来编写:</p>
<ul>
<li><p>通过LOAD语句从文件系统读取数据</p>
</li>
<li><p>通过一系列“转换”语句对数据进行处理</p>
</li>
<li><p>通过一条STORE语句把处理结果输出到文件系统中，或者使用DUMP语句把处理结果输出到屏幕上</p>
</li>
</ul>
<p>下面是一个采用Pig Latin语言编写的应用程序实例，实现对用户访问网页情况的统计分析：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">visits             = load ‘/data/visits’ as (user, url, time);</span><br><span class="line"></span><br><span class="line">gVisits          = group visits by url;</span><br><span class="line">visitCounts  = foreach gVisits generate url, count(visits);</span><br><span class="line">//得到的表的结构visitCounts(url,visits)</span><br><span class="line">urlInfo          = load ‘/data/urlInfo’ as (url, category, pRank);</span><br><span class="line">visitCounts  = join visitCounts by url, urlInfo by url;</span><br><span class="line">//得到的连接结果表的结构visitCounts(url,visits,category,pRank)</span><br><span class="line">gCategories = group visitCounts by category;</span><br><span class="line">topUrls = foreach gCategories generate top(visitCounts,10);</span><br><span class="line"></span><br><span class="line">store topUrls into ‘/data/topUrls’;</span><br></pre></td></tr></table></figure>
<h3 id="Pig应用场景"><a href="#Pig应用场景" class="headerlink" title="Pig应用场景"></a>Pig应用场景</h3><p>快速分析，不用直接写MapReduce任务。提高了效率，简化了流程。</p>
<h2 id="Tez"><a href="#Tez" class="headerlink" title="Tez"></a>Tez</h2><ul>
<li>支持DAG作用的计算框架，核心是将Map和Reduce两个操作进一步划分，行程一个大的DAG作业。使用在数据仓库Hive中的话，性能提升100倍。</li>
<li>Tez可以优化MapReduce、Pig和Hive的性能。</li>
<li>Tez仅能优化Map和Reduce作业。</li>
</ul>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><ul>
<li>内存计算，效率更高</li>
<li>基于DAG的任务调度执行机制，优于MapReduce的迭代执行机制。</li>
</ul>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><ul>
<li>Kafka是一种高吞吐量的分布式发布订阅消息系统，用户通过Kafka系统可以发布大量的消息，同时也能实时订阅消费消息。</li>
<li>Kafka可以同时满足在线实时处理和批量离线处理。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://boyl40.github.com/2019/06/22/大数据处理框架Hadoop的学习/" data-id="cjx74e1a90001kv618599mg5q" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Google-File-System" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/17/Google-File-System/" class="article-date">
  <time datetime="2019-06-17T13:59:27.000Z" itemprop="datePublished">2019-06-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/17/Google-File-System/">Google File System</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>[TOC]</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>我们设计并实现了Google GFS文件系统，一个面向大规模数据密集型应用的、可伸缩的分布式文件系统。GFS虽然运行在廉价的普遍硬件设备上，但是它依然了提供灾难冗余的能力，为大量客户机提供了高性能的服务。</p>
<p><strong>首先，组件失效被认为是常态事件，而不是意外事件。</strong>所以，持续的监控、错误侦测、灾难冗余以及自动恢复的机制必须集成在GFS中。</p>
<p><strong>其次，以通常的标准衡量</strong>，我们的文件非常巨大。</p>
<p><strong>第三，绝大部分文件的修改是采用在文件尾部追加数据，而不是覆盖原有数据的方式。</strong>数据的追加操作是性能优化和原子性保证的主要考量因素。</p>
<p><strong>第四，应用程序和文件系统API的协同设计提高了整个系统的灵活性。</strong></p>
<h1 id="设计概述"><a href="#设计概述" class="headerlink" title="设计概述"></a>设计概述</h1><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>我们支持常用的操作，如创建新文件、删除文件、打开文件、关闭文件、读和写文件。另外，GFS提供了快照和记录追加操作。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>一个GFS集群包含一个单独的<strong>Master</strong>节点、多台<strong>Chunk</strong>服务器，并且同时被多个客户端访问。</p>
<p>GFS存储的文件都被分割成固定大小的Chunk。在Chunk创建的时候，Master服务器会给每个Chunk分配一个不变的、全球唯一的64位的Chunk标识。Chunk服务器把Chunk以Linux文件的形式保存在本地硬盘上，并且根据指定的Chunk标识和字节范围来读写块数据。出于可靠性的考虑，每个块都会复制到多个块服务器上。缺省情况下，我们使用3个存储复制节点，不过用户可以为不同的文件命名空间设定不同的复制级别。</p>
<p><strong>Master</strong>节点管理所有的文件系统元数据。这些元数据包括名字空间、访问控制信息、文件和Chunk的映射信息、以及当前Chunk的位置信息。Master节点还管理着系统范围内的活动，比如，Chunk租用管理、孤儿Chunk的回收、以及Chunk在Chunk服务器之间的迁移。Master节点使用心跳信息周期地和每个Chunk服务器通讯，发送指令到各个Chunk服务器并接收Chunk服务器的状态信息。</p>
<p><strong>GFS客户端</strong>代码以库的形式被链接到客户程序里。客户端代码实现了GFS文件系统的API接口函数、应用程序与Master节点和Chunk服务器通讯、以及对数据进行读写操作。客户端和Master节点的通信只获取元数据，所有的数据操作都是由客户端直接和Chunk服务器进行交互的。我们不提供POSIX标准的API的功能，因此，GFS API调用不需要深入到Linux vnode级别。</p>
<p><strong>无论是客户端还是Chunk服务器都不需要缓存文件数据</strong>。客户端缓存数据几乎没有什么用处，因为大部分程序要么以流的方式读取一个巨大文件，要么工作集太大根本无法被缓存。无需考虑缓存相关的问题也简化了客户端和整个系统的设计和实现。Chunk服务器不需要缓存文件数据的原因是，Chunk以本地文件的方式保存，Linux操作系统的文件系统缓存会把经常访问的数据缓存在内存中。</p>
<h2 id="单一Master节点"><a href="#单一Master节点" class="headerlink" title="单一Master节点"></a>单一Master节点</h2><p>单一的Master节点的策略大大简化了我们的设计。另外，我们必须减少对Master节点的读写，避免Master节点成为系统的瓶颈。</p>
<h2 id="Chunk尺寸"><a href="#Chunk尺寸" class="headerlink" title="Chunk尺寸"></a>Chunk尺寸</h2><p>我们选择了64MB，这个尺寸远远大于一般文件系统的Block size。每个Chunk的副本都以普通Linux文件的形式保存在Chunk服务器上，只有在需要的时候才扩大。</p>
<p>然而，当我们第一次把GFS用于批处理队列系统的时候，热点的问题还是产生了：一个可执行文件在GFS上保存为single-chunk文件，之后这个可执行文件在数百台机器上同时启动。存放这个可执行文件的几个Chunk服务器被数百个客户端的并发请求访问导致系统局部过载。我们通过使用更大的复制参数来保存可执行文件，以及错开批处理队列系统程序的启动时间的方法解决了这个问题。一个可能的长效解决方案是，<strong>在这种的情况下，允许客户端从其它客户端读取数据。</strong></p>
<h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h2><p>Master服务器存储3种主要类型的元数据，包括：文件和Chunk的命名空间、文件和Chunk的对应关系、每个Chunk副本的存放地点。</p>
<h3 id="内存中的数据结构"><a href="#内存中的数据结构" class="headerlink" title="内存中的数据结构"></a>内存中的数据结构</h3><p>因为元数据保存在内存中，所以Master服务器的操作速度非常快。并且，Master服务器可以在后台简单而高效的周期性扫描自己保存的全部状态信息。这种周期性的状态扫描也用于实现Chunk垃圾收集、在Chunk服务器失效的时重新复制数据、通过Chunk的迁移实现跨Chunk服务器的负载均衡以及磁盘使用状况统计等功能。</p>
<h3 id="Chunk位置信息"><a href="#Chunk位置信息" class="headerlink" title="Chunk位置信息"></a>Chunk位置信息</h3><p><strong>Master</strong>服务器并不保存持久化保存哪个Chunk服务器存有指定Chunk的副本的信息。Master服务器只是在启动的时候轮询Chunk服务器以获取这些信息。Master服务器能够保证它持有的信息始终是最新的，因为它控制了所有的Chunk位置的分配，而且通过周期性的心跳信息监控Chunk服务器的状态。</p>
<h3 id="操作日志"><a href="#操作日志" class="headerlink" title="操作日志"></a>操作日志</h3><p>操作日志包含了关键的元数据变更历史记录。</p>
<p>Master服务器在灾难恢复时，通过重演操作日志把文件系统恢复到最近的状态。为了缩短Master启动的时间，我们必须使日志足够小。Master服务器在日志增长到一定量时对系统状态做一次Checkpoint，将所有的状态数据写入一个Checkpoint文件</p>
<h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><h3 id="GFS一致性保障机制"><a href="#GFS一致性保障机制" class="headerlink" title="GFS一致性保障机制"></a>GFS一致性保障机制</h3><p>件命名空间的修改（例如，文件创建）是原子性的。它们仅由Master节点的控制：命名空间锁提供了原子性和正确性的保障；Master节点的操作日志定义了这些操作在全局的顺序。</p>
<p>如果所有客户端，无论从哪个副本读取，读到的数据都一样，那么我们认为文件region是“一致的”；如果对文件的数据修改之后，region是一致的，并且客户端能够看到写入操作全部的内容，那么这个region是“已定义的”。</p>
<h3 id="程序的实现"><a href="#程序的实现" class="headerlink" title="程序的实现"></a>程序的实现</h3><p>尽量采用追加写入而不是覆盖，Checkpoint，自验证的写入操作，自标识的记录。</p>
<h1 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h1><p>一个重要的原则是最小化所有操作和Master节点的交互。</p>
<h2 id="租约（lease）和变更顺序"><a href="#租约（lease）和变更顺序" class="headerlink" title="租约（lease）和变更顺序"></a>租约（lease）和变更顺序</h2><p><img src="/images/image-201906225365.png" alt="image-201906225365.png"></p>
<h2 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h2><p>为了提高网络效率，我们采取了把<strong>数据流</strong>和<strong>控制流</strong>分开的措施。在控制流从客户机到主Chunk、然后再到所有二级副本的同时，数据以管道的方式，顺序的沿着一个精心选择的Chunk服务器链推送。我们的目标是充分利用每台机器的带宽，避免网络瓶颈和高延时的连接，最小化推送所有数据的延时。</p>
<p>我们利用基于TCP连接的、管道式数据推送方式来最小化延迟。</p>
<h2 id="原子的记录追加"><a href="#原子的记录追加" class="headerlink" title="原子的记录追加"></a>原子的记录追加</h2><p><strong>GFS</strong>提供了一种原子的数据追加操作–记录追加。</p>
<h2 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h2><p>快照操作几乎可以瞬间完成对一个文件或者目录树（“源”）做一个拷贝，并且几乎不会对正在进行的其它操作造成任何干扰。</p>
<h1 id="Master节点的操作"><a href="#Master节点的操作" class="headerlink" title="Master节点的操作"></a>Master节点的操作</h1><p>Master节点执行所有的名称空间操作。此外，它还管理着整个系统里所有Chunk的副本：它决定Chunk的存储位置，创建新Chunk和它的副本，协调各种各样的系统活动以保证Chunk被完全复制，在所有的Chunk服务器之间的进行负载均衡，回收不再使用的存储空间。</p>
<h2 id="名称空间管理和锁"><a href="#名称空间管理和锁" class="headerlink" title="名称空间管理和锁"></a>名称空间管理和锁</h2><p>Master节点的很多操作会花费很长的时间：比如，快照操作必须取消Chunk服务器上快照所涉及的所有的Chunk的租约。我们不希望在这些操作的运行时，延缓了其它的Master节点的操作。因此，我们允许多个操作同时进行，使用名称空间的region上的锁来保证执行的正确顺序。</p>
<h2 id="副本的位置"><a href="#副本的位置" class="headerlink" title="副本的位置"></a>副本的位置</h2><p>Chunk副本位置选择的策略服务两大目标：最大化数据可靠性和可用性，最大化网络带宽利用率。另一方面，写操作必须和多个机架上的设备进行网络通信，但是这个代价是我们愿意付出的。</p>
<h2 id="创建，重新复制，重新负载均衡"><a href="#创建，重新复制，重新负载均衡" class="headerlink" title="创建，重新复制，重新负载均衡"></a>创建，重新复制，重新负载均衡</h2><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><h1 id="度量（benchmark）"><a href="#度量（benchmark）" class="headerlink" title="度量（benchmark）"></a>度量（benchmark）</h1>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://boyl40.github.com/2019/06/17/Google-File-System/" data-id="cjx74e1ap0005kv61hk049cp1" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GFS/">GFS</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-MapReduce：大型集群上的简化数据处理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/31/MapReduce：大型集群上的简化数据处理/" class="article-date">
  <time datetime="2019-05-31T10:11:36.000Z" itemprop="datePublished">2019-05-31</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/31/MapReduce：大型集群上的简化数据处理/">MapReduce：大型集群上的简化数据处理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>MapReduce</strong>是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。用户首先创建一个Map函数处理一个基于key/value pair的数据集合，输出中间的基于key/value pair的数据集合；然后再创建一个Reduce函数用来合并所有的具有相同中间key值的中间value值。</p>
<p>MapReduce架构的程序能够在大量的普通配置的计算机上实现并行化处理。这个系统在运行时只关心：如何分割输入数据，在大量计算机组成的集群上的调度，集群中计算机的错误处理，管理集群中计算机之间必要的通信。采用MapReduce架构可以使那些没有并行计算和分布式处理系统开发经验的程序员有效利用分布式系统的丰富资源。</p>
<p>我们的MapReduce实现运行在规模可以灵活调整的由普通机器组成的集群上：一个典型的MapReduce计算往往由几千台机器组成、处理以TB计算的数据。程序员发现这个系统非常好用：已经实现了数以百计的MapReduce程序，在Google的集群上，每天都有1000多个MapReduce程序在执行。</p>
<h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p><strong>MapReduce</strong>编程模型的原理是：利用一个输入key/value  pair集合来产生一个输出的key/value  pair集合。MapReduce库的用户用两个函数表达这个计算：Map和Reduce。</p>
<p>用户自定义的<strong>Map</strong>函数接受一个输入的key/valuepair值，然后产生一个中间key/value pair值的集合。MapReduce库把所有具有相同中间key值I的中间value值集合在一起后传递给reduce函数。</p>
<p>用户自定义的<strong>Reduce</strong>函数接受一个中间key的值I和相关的一个value值的集合。Reduce函数合并这些value值，形成一个较小的value值的集合。一般的，每次Reduce函数调用只产生0或1个输出value值。通常我们通过一个迭代器把中间value值提供给Reduce函数，这样我们就可以处理无法全部放入内存中的大量的value值的集合。</p>
<h3 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">map(k1,v1) -&gt; list(k2,v2)</span><br><span class="line">reduce(k2,list(v2)) -&gt; list(v2)</span><br></pre></td></tr></table></figure>
<p>比如，输入的key和value值与输出的key和value值在类型上推导的域不同。此外，中间key和value值与输出key和value值在类型上推导的域相同。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="执行概括"><a href="#执行概括" class="headerlink" title="执行概括"></a>执行概括</h3><p>通过将Map调用的输入数据自动分割为M个数据片段的集合，Map调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将Map调用产生的中间key值分成R个不同分区（例如，hash(key) mod R），Reduce调用也被分布到多台机器上执行。分区数量（R）和分区函数由用户来指定。</p>
<p><img src="/images/image-20190615232130215.png" alt="image-20190615232130215"></p>
<p>图上展示了我们的MapReduce实现中操作的全部流程。当用户调用MapReduce函数时，将发生下面的一系列动作（下面的序号和图1中的序号一一对应）：</p>
<ol>
<li><p>用户程序首先调用的MapReduce库将输入文件分成M个数据片度，每个数据片段的大小一般从16MB到64MB(可以通过可选的参数来控制每个数据片段的大小)。然后用户程序在机群中创建大量的程序副本。</p>
</li>
<li><p>这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是worker程序，由master分配任务。有M个Map任务和R个Reduce任务将被分配，master将一个Map任务或Reduce任务分配给一个空闲的worker。</p>
</li>
<li><p>被分配了map任务的worker程序读取相关的输入数据片段，从输入的数据片段中解析出key/value pair，然后把key/value pair传递给用户自定义的Map函数，由Map函数生成并输出的中间key/value pair，并缓存在内存中。</p>
</li>
<li><p>缓存中的key/value  pair通过分区函数分成R个区域，之后周期性的写入到本地磁盘上。缓存的key/value  pair在本地磁盘上的存储位置将被回传给master，由master负责把这些存储位置再传送给Reduce worker。</p>
</li>
<li><p>当Reduce worker程序接收到master程序发来的数据存储位置信息后，使用RPC从Map worker所在主机的磁盘上读取这些缓存数据。当Reduce worker读取了所有的中间数据后，通过对key进行排序后使得具有相同key值的数据聚合在一起。由于许多不同的key值会映射到相同的Reduce任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。</p>
</li>
<li><p>Reduce worker程序遍历排序后的中间数据，对于每一个唯一的中间key值，Reduce worker程序将这个key值和它相关的中间value值的集合传递给用户自定义的Reduce函数。Reduce函数的输出被追加到所属分区的输出文件。</p>
</li>
<li><p>当所有的Map和Reduce任务都完成之后，master唤醒用户程序。在这个时候，在用户程序里的对MapReduce调用才返回。</p>
</li>
</ol>
<p>在成功完成任务之后，MapReduce的输出存放在R个输出文件中（对应每个Reduce任务产生一个输出文件，文件名由用户指定）。一般情况下，用户不需要将这R个输出文件合并成一个文件–他们经常把这些文件作为另外一个MapReduce的输入，或者在另外一个可以处理多个分割文件的分布式应用中使用。</p>
<h3 id="Master数据结构"><a href="#Master数据结构" class="headerlink" title="Master数据结构"></a>Master数据结构</h3><p>Master持有一些数据结构，它存储每一个Map和Reduce任务的状态（空闲、工作中或完成)，以及Worker机器(非空闲任务的机器)的标识。</p>
<p>Master就像一个数据管道，中间文件存储区域的位置信息通过这个管道从Map传递到Reduce。因此，对于每个已经完成的Map任务，master存储了Map任务产生的R个中间文件存储区域的大小和位置。当Map任务完成时，Master接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的Reduce任务。</p>
<h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><h4 id="work故障"><a href="#work故障" class="headerlink" title="work故障"></a>work故障</h4><p>master周期性的ping每个worker。如果在一个约定的时间范围内没有收到worker返回的信息，master将把这个worker标记为失效。</p>
<p>当一个Map任务首先被worker A执行，之后由于worker A失效了又被调度到worker B执行，这个“重新执行”的动作会被通知给所有执行Reduce任务的worker。任何还没有从worker A读取数据的Reduce任务将从worker B读取数据。</p>
<h4 id="master失败"><a href="#master失败" class="headerlink" title="master失败"></a>master失败</h4><p>一个简单的解决办法是让master周期性的将上面描述的数据结构写入磁盘，即检查点（checkpoint）。如果这个master任务失效了，可以从最后一个检查点（checkpoint）开始启动另一个master进程。然而，由于只有一个master进程，master失效后再恢复是比较麻烦的，因此我们现在的实现是如果master失效，就中止MapReduce运算。客户可以检查到这个状态，并且可以根据需要重新执行MapReduce操作。</p>
<h4 id="在失效方面的处理机制"><a href="#在失效方面的处理机制" class="headerlink" title="在失效方面的处理机制"></a>在失效方面的处理机制</h4><p>我们依赖对Map和Reduce任务的输出是原子提交的来完成这个特性。每个工作中的任务把它的输出写到私有的临时文件中。每个Reduce任务生成一个这样的文件，而每个Map任务则生成R个这样的文件（一个Reduce任务对应一个文件）。当一个Map任务完成的时，worker发送一个包含R个临时文件名的完成消息给master。如果master从一个已经完成的Map任务再次接收到到一个完成消息，master将忽略这个消息；否则，master将这R个文件的名字记录在数据结构里。</p>
<h3 id="存储位置"><a href="#存储位置" class="headerlink" title="存储位置"></a>存储位置</h3><p>我们通过尽量把输入数据(由GFS管理)存储在集群中机器的本地磁盘上来节省网络带宽。GFS把每个文件按64MB一个Block分隔，每个Block保存在多台机器上，环境中就存放了多份拷贝(一般是3个拷贝)。MapReduce的master在调度Map任务时会考虑输入文件的位置信息，尽量将一个Map任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败了，master将尝试在保存有输入数据拷贝的机器附近的机器上执行Map任务(例如，分配到一个和包含输入数据的机器在一个switch里的worker机器上执行)。当在一个足够大的cluster集群上运行大型MapReduce操作的时候，大部分的输入数据都能从本地机器读取，因此消耗非常少的网络带宽。</p>
<h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><h3 id="分区函数"><a href="#分区函数" class="headerlink" title="分区函数"></a>分区函数</h3><p>MapReduce的使用者通常会指定Reduce任务和Reduce任务输出文件的数量（R）。我们在中间key上使用分区函数来对数据进行分区，之后再输入到后续任务执行进程。一个缺省的分区函数是使用hash方法(比如，hash(key)  mod  R)进行分区。hash方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对key值进行的分区将非常有用。比如，输出的key值是URLs，我们希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，MapReduce库的用户需要提供专门的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数就可以把所有来自同一个主机的URLs保存在同一个输出文件中。</p>
<h3 id="Combiner函数"><a href="#Combiner函数" class="headerlink" title="Combiner函数"></a>Combiner函数</h3><p>每个Map任务将产生成千上万个这样的记录&lt;the,1&gt;。所有的这些记录将通过网络被发送到一个单独的Reduce任务，然后由这个Reduce任务把所有这些记录累加起来产生一个数字。我们允许用户指定一个可选的combiner函数，combiner函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</p>
<p>Combiner函数在每台执行Map任务的机器上都会被执行一次。一般情况下，Combiner和Reduce函数是一样的。Combiner函数和Reduce函数之间唯一的区别是MapReduce库怎样控制函数的输出。Reduce函数的输出被保存在最终的输出文件里，而Combiner函数的输出被写到中间文件里，然后被发送给Reduce任务。</p>
<h3 id="跳过损坏的记录"><a href="#跳过损坏的记录" class="headerlink" title="跳过损坏的记录"></a>跳过损坏的记录</h3><p>每个worker进程都设置了信号处理函数捕获内存段异常（segmentation violation）和总线错误（bus error）。在执行Map或者Reduce操作之前，MapReduce库通过全局变量保存记录序号。如果用户程序触发了一个系统信号，消息处理函数将用“最后一口气”通过UDP包向master发送处理的最后一条记录的序号。当master看到在处理某条特定记录不止失败一次时，master就标志着条记录需要被跳过，并且在下次重新执行相关的Map或者Reduce任务的时候跳过这条记录。</p>
<h3 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h3><p>处于最顶层的状态页面显示了哪些worker失效了，以及他们失效的时候正在运行的Map和Reduce任务。这些信息对于调试用户代码中的bug很有帮助。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>MapReduce</strong>的实现依赖于一个内部的集群管理系统，这个集群管理系统负责在一个超大的、共享机器的集群上分布和运行用户任务。虽然这个不是本论文的重点，但是有必要提一下，这个集群管理系统在理念上和其它系统，如Condor是一样。</p>
<p><strong>MapReduce</strong>库的排序机制和NOW-Sort的操作上很类似。读取输入源的机器（map  workers）把待排序的数据进行分区后，发送到R个Reduce worker中的一个进行处理。每个Reduce worker在本地对数据进行排序（尽可能在内存中排序）。当然，NOW-Sort没有给用户自定义的Map和Reduce函数的机会，因此不具备MapReduce库广泛的实用性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://boyl40.github.com/2019/05/31/MapReduce：大型集群上的简化数据处理/" data-id="cjx74e1ar0006kv614p5e3vv7" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MapReduce/">MapReduce</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-新文章" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/05/30/新文章/" class="article-date">
  <time datetime="2019-05-30T06:33:00.000Z" itemprop="datePublished">2019-05-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/05/30/新文章/">新文章</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>123</p>
<p>456</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://boyl40.github.com/2019/05/30/新文章/" data-id="cjx74e1ab0002kv618qzcidny" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  
    <article id="post-flask_celery_使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/04/11/flask_celery_使用/" class="article-date">
  <time datetime="2019-04-11T06:51:51.461Z" itemprop="datePublished">2019-04-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/11/flask_celery_使用/">Celery的使用心得</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>[TOC]</p>
<p>本文的代码托管在<a href="https://github.com/shilinlee/code-note/tree/master/python/celery_demo" target="_blank" rel="noopener">这里</a></p>
<h3 id="Celery介绍"><a href="#Celery介绍" class="headerlink" title="Celery介绍"></a>Celery介绍</h3><p>Celery 是一个由 Python 编写的简单、灵活、可靠的用来处理大量信息的分布式系统，它同时提供操作和维护分布式系统所需的工具。Celery是一个分布式队列的管理工具。</p>
<h3 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h3><h4 id="Brokers"><a href="#Brokers" class="headerlink" title="Brokers"></a>Brokers</h4><p>在这里是指任务队列。brokers就是生产者和消费者存放、拿取产品的地方(队列)。</p>
<h4 id="Result-Stores-backend"><a href="#Result-Stores-backend" class="headerlink" title="Result Stores / backend"></a>Result Stores / backend</h4><p>结果储存的地方。</p>
<p>常见的 backend 有 redis、Memcached, 甚至常用的数据都可以。</p>
<h4 id="Workers"><a href="#Workers" class="headerlink" title="Workers"></a>Workers</h4><p>就是 Celery 中的工作者，类似与生产/消费模型中的消费者，其从队列中取出任务并执行。</p>
<h4 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h4><p>就是我们想在队列中进行的任务咯，一般由用户、触发器或其他操作将任务入队，然后交由 workers 进行处理。</p>
<h4 id="一个简单的用法"><a href="#一个简单的用法" class="headerlink" title="一个简单的用法"></a>一个简单的用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># task.py</span><br><span class="line">from flask import Flask</span><br><span class="line">from flask_celery_api import make_celery</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">flask_app = Flask(__name__)</span><br><span class="line">flask_app.config.update(</span><br><span class="line">    CELERY_BROKER_URL=&apos;redis://localhost:6379&apos;,</span><br><span class="line">    CELERY_RESULT_BACKEND=&apos;redis://localhost:6379&apos;</span><br><span class="line">)</span><br><span class="line">celery = make_celery(flask_app)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@celery.task()</span><br><span class="line">def add_together(a, b):</span><br><span class="line">    print(a+b)</span><br><span class="line">    return a + b</span><br></pre></td></tr></table></figure>
<p>以上代码就完成了brokers、backend、task的准备了。下面可以运行worker了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ celery -A task worker --loglevel=info</span><br></pre></td></tr></table></figure>
<p>运行结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> -------------- celery@shilinleedeMBP v4.3.0 (rhubarb)</span><br><span class="line">---- **** ----- </span><br><span class="line">--- * ***  * -- Darwin-17.7.0-x86_64-i386-64bit 2019-04-15 19:28:57</span><br><span class="line">-- * - **** --- </span><br><span class="line">- ** ---------- [config]</span><br><span class="line">- ** ---------- .&gt; app:         task:0x10f63c940</span><br><span class="line">- ** ---------- .&gt; transport:   redis://localhost:6379//</span><br><span class="line">- ** ---------- .&gt; results:     redis://localhost:6379/</span><br><span class="line">- *** --- * --- .&gt; concurrency: 8 (prefork)</span><br><span class="line">-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)</span><br><span class="line">--- ***** ----- </span><br><span class="line"> -------------- [queues]</span><br><span class="line">                .&gt; celery           exchange=celery(direct) key=celery</span><br></pre></td></tr></table></figure>
<p>worker此时相当于待命状态。</p>
<p>最后一步，就是触发任务啦，最简单方式就是再写一个脚本然后调用那个被装饰成 task 的函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># excute.py</span><br><span class="line">from task import add_together</span><br><span class="line"></span><br><span class="line">result = add_together.delay(10, 20)</span><br><span class="line">print(result.wait())</span><br></pre></td></tr></table></figure>
<p>运行此脚本即可。一个简单的 celery 应用就完成啦。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://boyl40.github.com/2019/04/11/flask_celery_使用/" data-id="cjx74e1a40000kv61h1avntq7" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>
 


  

</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/giscafer" target="_blank" title="Github"></a>
      
      
            <a class="weibo" aria-hidden="true" href="http://weibo.com/laohoubin" target="_blank" title="微博"></a>
      
      
              <a class="zhihu" aria-hidden="true" href="http://www.zhihu.com/people/giscafer" target="_blank" title="知乎"></a>
      
      
            <a class="email" aria-hidden="true" href="mailto:youemail@outlook.com" target="_blank" title="邮箱"></a>
      
    </div>
  </div>


  
    
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/GFS/" style="font-size: 14px;">GFS</a> <a href="/tags/Hadoop/" style="font-size: 14px;">Hadoop</a> <a href="/tags/MapReduce/" style="font-size: 14px;">MapReduce</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/06/22/大数据处理框架Hadoop的学习/">大数据处理框架Hadoop的学习</a>
          </li>
        
          <li>
            <a href="/2019/06/17/Google-File-System/">Google File System</a>
          </li>
        
          <li>
            <a href="/2019/05/31/MapReduce：大型集群上的简化数据处理/">MapReduce：大型集群上的简化数据处理</a>
          </li>
        
          <li>
            <a href="/2019/05/30/新文章/">新文章</a>
          </li>
        
          <li>
            <a href="/2019/04/11/flask_celery_使用/">Celery的使用心得</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="http://blog.giscafer.com">giscafer&#39;s blog</a>
            </li>
            
            <li>
                <a href="http://www.gis520.com">GIS520社区</a>
            </li>
            
        </ul>
    </div>
</div>

  
    <!--微信公众号二维码-->

  <div class="widget-wrap">
    <h3 class="follow-title ">WeChat</h3>
    <div class="widget wechat-widget">
        <img src="http://blog.giscafer.com/static/images/qrcode_giscafer.jpg" alt="扫码关注" width="250">
    </div>
  </div>


  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2019 Shilin Lee&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;youemail@outlook.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png">
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div>
</body>
</html>