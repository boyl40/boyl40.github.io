---
cover: https://github.com/microsoft/generative-ai-for-beginners/blob/main/images/repo-thubmnail2.png?raw=true
icon: pen-to-square
date: 2024-04-05
category:
  - AI
  - LLM
tag:
  - 初学者
  - 入门
  - RAG
---

# 初学者的生成式AI课程

通过微软云技术布道师团队提供的十二章系列课程，了解构建生成式 AI 应用程序的基础知识。 每章都涵盖了生成式人工智能原理和应用程序开发的一个关键方面。 在整个系列课程中，我们将建立我们自己的生成式人工智能初创公司，以便您可以了解如何实现您的想法。

<!-- more -->

## [第一章：生成式人工智能和 LLMs 介绍](https://microsoft.github.io/generative-ai-for-beginners/#/01-introduction-to-genai/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第一章-生成式人工智能和-llms-介绍)

生成式人工智能的发展经历了漫长的历程，从最早的基于规则的聊天机器人到现代的深度学习模型，如 OpenAI 的 GPT 系列模型。以下是生成式人工智能的发展概述：

1. **基于规则的系统**：早期的人工智能系统依赖于基于规则的方法，其中专家系统中的知识库被用于根据输入文本中的关键字来生成响应。这种方法在扩展性和灵活性上存在限制。
2. **统计学和机器学习**：20 世纪 90 年代，随着统计学在文本分析中的应用，机器学习算法的发展成为可能。这些算法能够从数据中学习模式，而不需要显式的编程。这种方法为机器模拟人类语言理解打开了新的可能性。
3. **神经网络和深度学习**：近年来，随着硬件技术的发展，深度学习算法，特别是基于神经网络的方法，开始得到广泛应用。循环神经网络 (RNN) 在自然语言处理领域发挥着重要作用，能够更好地表示文本含义。
4. **生成式人工智能**：生成式人工智能是深度学习的一个子集，其中的模型被训练来预测给定一段文本后面可能出现的文本。最近的 Transformer 模型架构克服了 RNN 的一些限制，使得模型能够处理更长的文本序列。这些模型通过大量的未标记数据进行训练，可以以创造性的方式生成语法正确的文本。

在生成式人工智能中，文本首先被分词器处理成标记数组，然后模型基于当前文本序列预测下一个标记。选择过程中，模型根据概率分布来选择输出标记，增加一定程度的随机性以模拟人类创造性思维的过程。

总的来说，生成式人工智能的发展经历了多个阶段，从基于规则的系统到深度学习模型，不断提高了对文本理解和生成的能力。

## [第二章：探索和比较不同的 LLMs](https://microsoft.github.io/generative-ai-for-beginners/#/02-exploring-and-comparing-different-llms/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第二章-探索和比较不同的-llms)

### 大型语言模型的种类

认识不同类型的大型语言模型（LLMs）是选择正确模型的关键。下面是一些主要分类：

1. **基于用例的分类**：
   - **音频和语音识别**：用于语音识别的模型，如Whisper。
   - **图像生成**：用于图像生成的模型，如DALL-E和Midjourney。
   - **文本生成**：用于文本生成的模型，如GPT系列（GPT-3.5、GPT-4等）。
2. **基于架构的分类**：
   - **嵌入模型**：用于将文本转换为数字形式的模型，如OpenAI Embeddings。
   - **图像生成模型**：主要用于生成图像的模型，如DALL-E。
   - **文本或代码生成模型**：用于生成文本或代码的模型，如GPT系列和CodeParrot。
3. **开源模型与专有模型**：
   - **开源模型**：向公众开放并可自由使用的模型，例如Alpaca、Bloom和LLaMA。
   - **专有模型**：由公司拥有的模型，通常用于生产目的，例如OpenAI模型和Google Bard。
4. **编码-解码器与独立解码器**：
   - **编码-解码器模型**：具有编码器和解码器组件，例如BART和T5，用于创建和审阅文本。
   - **独立解码器模型**：只有解码器组件，例如GPT系列，主要用于生成文本。
   - **独立编码器模型**：只有编码器组件，例如BERT，主要用于理解文本。
5. **服务与模型**：
   - **服务**：云服务提供商提供的产品，通常结合了模型、数据和其他组件。例如，Azure OpenAI服务。
   - **模型**：神经网络等具有参数和权重的模型，可以在本地运行或通过服务使用。

选择正确的模型取决于你的需求、数据、预算以及是否需要针对特定场景进行定制。同时，了解不同类型的LLMs可以帮助你更好地理解其适用范围和性能特点，从而做出更明智的选择。

### 提升LLM输出结果的准确度

提升大型语言模型（LLM）输出结果的准确度是关键，特别是在企业生产环境中。以下是一些方法：

1. **根据上下文进行工程设计**：提供详细的请求和示例（上下文），以便模型更准确地理解用户需求。这种方法对于零样本学习和少样本学习非常有效。
2. **检索增强生成 (RAG)**：利用检索增强生成技术，通过引入外部数据块来增强提示上下文，从而提高模型的性能。这可以通过使用矢量数据库工具等实现，使模型能够获取非公开信息并生成更准确的答案。
3. **微调模型**：通过微调预训练的模型来适应特定任务或问题。这种方法需要一组训练示例，可以是单个输入（提示）及其关联的输出（完成）。微调可以使模型更适合特定工作负载，提高性能并减少错误。
4. **训练垂直行业模型**：对于特定行业的用例，考虑从头开始训练专门的模型。这需要大量领域特定的数据和资源，但可以确保模型与行业相关并且具有高准确度。
5. **使用更大的模型**：在预算允许的情况下，考虑使用更大、更复杂的模型，如GPT-4，以提高模型的性能和准确度。
6. **持续监控和调整**：在模型部署后，进行持续的监控和调整，以确保其性能始终符合预期，并且随着时间推移可能需要进行微调或更新。

### 知识拓展

详细了解如何为您的业务 [使用 RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst)。

## [第三章：负责任地使用生成式人工智能](https://microsoft.github.io/generative-ai-for-beginners/#/03-using-generative-ai-responsibly/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第三章-：-负责任地使用生成式人工智能)

负责任地使用生成式人工智能（Generative AI）对于保护用户和社会利益至关重要。以下是为什么应该优先考虑负责任的人工智能：

1. **保护用户利益**：负责任的人工智能确保用户在与系统交互时受到尊重和保护。这意味着确保系统产生的内容准确、合法，并不会对用户造成伤害或误导。
2. **建立信任**：负责任的人工智能有助于建立用户对系统的信任。用户需要相信系统能够提供准确、可靠且有价值的信息，而不会受到误导或被操纵。
3. **避免社会风险**：不负责任的人工智能可能会导致社会问题，如误导性信息、仇恨言论或对边缘群体的歧视。通过采取负责任的方法，可以减少这些风险，并确保人工智能对社会产生积极影响。
4. **符合监管要求**：随着人工智能应用越来越普及，监管机构对人工智能系统的责任和合规性提出了更高的要求。负责任的人工智能有助于满足这些监管要求，避免可能的法律和道德问题。
5. **增加产品价值**：负责任的人工智能不仅可以提供更好的用户体验，还可以增加产品的价值和可持续性。通过确保系统的可靠性和安全性，可以吸引更多用户并提高用户满意度。

因此，企业在构建人工智能解决方案时应该始终优先考虑负责任的方法。这包括对系统的设计、开发、部署和监管都要考虑到用户和社会的最大利益，并努力避免潜在的负面影响。

## [第四章：提示工程基础](https://microsoft.github.io/generative-ai-for-beginners/#/04-prompt-engineering-fundamentals/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第四章：提示工程基础)

### 什么是提示工程

提示工程是指设计和优化文本输入（提示）的过程，以确保为指定的应用程序目标和模型提供一致且高质量的响应（完成）。它是一个包括两个主要步骤的过程：

1. 设计初始提示：根据指定的模型和应用程序目标，设计初始提示以启动模型生成所需的响应。这个过程需要考虑到模型的标记化方式以及其处理输入的方式。
2. 迭代优化提示：通过反复尝试和调整提示，以提高生成的响应质量和适应特定任务或目标。这可能涉及尝试不同的提示结构、样式、长度等，以最大程度地减少模型产生的幻觉或不准确响应的可能性。

提示工程对于生成式人工智能模型的应用非常重要，因为它可以帮助确保模型产生的响应符合用户期望并且与应用程序的目标一致。通过优化提示，可以降低模型产生幻觉或不准确响应的风险，从而提高系统的可靠性和用户满意度。

### 构建提示的方法

构建提示的方法可以分为以下几种类型：

1. 基础提示：基础提示是发送到模型的简单文本输入，没有其他上下文。这种提示不包含任何额外的信息，只是一个简单的输入，用于触发模型生成响应。例如，将一句歌词发送给生成式人工智能模型，以让它继续歌词。
2. 复杂的提示：复杂的提示将基础提示与上下文和说明结合起来，以提供更详细的信息和指导。这种提示可以构建为输入/输出对，其中包含反映用户输入和助理响应的对话历史。此外，可以添加系统消息来设置助理的行为或个性化。通过添加上下文信息，复杂的提示可以帮助模型更好地理解用户的意图和任务，并生成更准确和个性化的响应。
3. 指令式的提示：指令式的提示是为特定任务或目标而设计的，以提供更具体的指导和要求。这种类型的提示更详细和特定，可以包括任务描述、要求提供特定信息的指令、格式要求等。指令式的提示可以进一步细化为简单或复杂类型，取决于任务的复杂性和要求的详细程度。例如，**要求生成一个描述文本并提供关键日期和事件的段落，或者要求以 JSON 格式返回特定的信息。**

### 最佳实践

在设计和构建提示时，以下是一些最佳实践：

1. 评估最新模型：定期评估最新的生成式人工智能模型。新的模型可能具有改进的功能和质量，但可能会带来更高的成本。评估它们的影响，然后做出迁移决策。
2. 分离指令和上下文：确保模型或提供者定义了分隔符，以更清晰地区分指令、主要内容和次要内容。这有助于模型更准确地分配权重给标记。
3. 具体而清晰：提供有关所需上下文、结果、长度、格式、样式等的更多细节。这将提高响应的质量和一致性。将模板捕获为可重复使用的模式。
4. 描述性和使用示例：模型可能更喜欢“展示和讲解”的方法。首先尝试零-shot方法，其中您只提供指令（但没有示例），然后尝试几个-shot作为细化，提供几个期望输出的示例。使用类比。
5. 使用线索启动补全：通过提供一些引导词或短语来推动模型朝向期望的结果。这些线索可以作为响应的起点。
6. 加倍努力：有时您可能需要重复向模型提供信息。在主要内容之前和之后给出指令，使用指令和线索等。迭代和验证，看看哪种方法最有效。
7. 顺序很重要：向模型呈现信息的顺序可能会影响输出，甚至在学习示例中也是如此，这要归功于新近偏见。尝试不同的选项，看看哪种效果最好。
8. 给模型一个“退出”的选择：如果由于任何原因模型无法完成任务，请为模型提供一个备用的完成响应。这可以减少模型生成错误或虚构响应的可能性。

请记住，任何最佳实践都可能因模型、任务和领域而异。使用这些作为起点，并根据需要进行迭代以找到最适合您的方法。随着新模型和工具的出现，不断重新评估您的提示工程，重点关注可扩展性和响应质量。

## [第五章：创建高级的提示工程技巧](https://microsoft.github.io/generative-ai-for-beginners/#/05-advanced-prompts/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第五章：创建高级的提示工程技巧)

提示工程是一个复杂的过程，涉及到使用不同的技术和技巧来引导生成式人工智能（LLM）产生所需的输出。以下是一些提示工程中常用的技巧和方法：

1. **少样本提示**：提供少量示例来引导LLM生成所需的内容。这是最基本的提示形式之一。
2. **思维链**：将问题分解为一系列步骤，并引导LLM逐步解决问题。这种方法有助于LLM更好地理解问题的结构和逻辑。
3. **生成的知识**：在提示中提供额外的信息或知识，以帮助LLM更准确地理解和生成内容。这可以是来自公司数据或特定领域的知识。
4. **从最少到最多**：将问题分解为多个子问题，并逐步引导LLM解决每个子问题。这有助于减少复杂问题的难度，并使LLM能够更有效地生成所需的内容。
5. **自我完善**：要求LLM生成初始答案，并根据反馈指导LLM进行改进。这种方法可以帮助LLM不断提高生成内容的质量。
6. **多维度提示**：要求LLM解释其生成内容的各个方面，并确保生成的内容是准确和一致的。这有助于降低LLM生成错误内容的风险。
7. **改变输出的确定性**：通过调整温度等参数来改变LLM生成内容的确定性和变化性。这可以使生成的内容更加可控和稳定。

在进行提示工程时，通常需要结合使用多种技巧和方法，并根据具体情况和需求进行调整和优化。



您可以应用许多实践来尝试获得您想要的东西。 当你越来越多地使用提示时，你会发现自己的风格。

除了我们介绍的技术之外，在调用 LLMs 时还需要考虑一些好的做法。

以下是一些值得考虑的良好做法：

- **指定上下文**。 上下文很重要，您可以指定的领域、主题等越多越好。
- 限制输出。 如果您想要特定数量的项目或特定长度，请指定。
- **指定内容和方式**。 请记住提及您想要什么以及您想要如何实现，例如“创建一个包含路由产品和客户的 Python Web API，将其分为 3 个文件”。
- **使用模板**。 通常，您会希望使用公司的数据来丰富提示。 使用模板来执行此操作。 模板可以包含用实际数据替换的变量。
- **拼写正确**。 LLMs 可能会为您提供正确的答案，但如果您拼写正确，您会得到更好的答案。

## [第六章：创建文本生成应用](https://microsoft.github.io/generative-ai-for-beginners/#/06-text-generation-apps/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第六章：创建文本生成应用)

文本生成应用程序是指利用文本生成技术，如生成式人工智能（GPT）等，来构建可以生成自然语言文本的应用程序。与传统的基于命令或图形用户界面（GUI）的应用程序不同，文本生成应用程序可以通过自然语言交互，使用户能够以更自然的方式与应用程序进行沟通和交互。

文本生成应用程序具有以下优势：

1. **灵活性**：用户不再受限于输入特定的命令或遵循特定的UI操作。他们可以使用自然语言来表达他们的需求，从而提供了更大的灵活性和便利性。
2. **智能交互**：文本生成应用程序通常使用机器学习模型来理解和生成文本，因此能够提供更智能、更个性化的交互体验。这些应用程序可以根据用户输入的上下文和意图提供相关的响应。
3. **多领域支持**：由于文本生成模型可以在多个领域进行训练，因此文本生成应用程序可以涵盖多个领域，包括问答系统、聊天机器人、自动摘要生成器等。

一些常见的文本生成应用程序包括：

- **聊天机器人**：用于回答用户的问题、提供建议或进行闲聊。
- **协同助手**：可以帮助用户总结文本、提取信息、生成文档等。
- **代码助手**：可以根据用户的描述或需求生成代码片段或提供编程建议。

入门构建文本生成应用程序的方法通常包括使用API或库：

- **API**：使用文本生成API，如OpenAI的GPT API，通过向API发送文本提示来获取生成的文本。
- **库**：使用文本生成库，如Hugging Face的Transformers库，可以更方便地在本地环境中使用文本生成模型。

通过这些方法，开发人员可以构建各种类型的文本生成应用程序，以满足不同用户和场景的需求。



temperature 有什么作用？

1. 它控制输出的随机程度。
2. 它控制响应的大小。
3. 它控制使用多少 tokens 。

A: 1

## [第七章：创建聊天应用](https://microsoft.github.io/generative-ai-for-beginners/#/07-building-chat-applications/translations/cn/README?wt.mc_id=academic-105485-koreyst&id=第七章：创建聊天应用)